{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import scipy as sp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from rich import print, progress\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Prep "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sequence(seq, max_length=1000):\n",
    "    # Define a mapping for common amino acids\n",
    "    amino_acids = \"ACDEFGHIKLMNPQRSTVWY\"\n",
    "    aa_to_int = {aa: i + 1 for i, aa in enumerate(amino_acids)}  # reserve 0 for padding\n",
    "\n",
    "    # Convert each amino acid in the sequence to its corresponding integer\n",
    "    encoded = [aa_to_int.get(aa, 0) for aa in seq]  # default to 0 if amino acid not found\n",
    "\n",
    "    # Pad or truncate the sequence to max_length\n",
    "    if len(encoded) < max_length:\n",
    "        encoded += [0] * (max_length - len(encoded))\n",
    "    else:\n",
    "        encoded = encoded[:max_length]\n",
    "    return encoded\n",
    "\n",
    "\n",
    "class PiNUIDataset(Dataset):\n",
    "    def __init__(self, seqA, seqB, targets, max_length=1000):\n",
    "        # Encode sequences from strings to numerical lists\n",
    "        self.seqA = [encode_sequence(seq, max_length) for seq in seqA]\n",
    "        self.seqB = [encode_sequence(seq, max_length) for seq in seqB]\n",
    "        self.targets = targets\n",
    "\n",
    "        # Convert the numerical lists and targets to tensors\n",
    "        self.seqA = torch.tensor(self.seqA, dtype=torch.float32)\n",
    "        self.seqB = torch.tensor(self.seqB, dtype=torch.float32)\n",
    "        self.targets = torch.tensor(self.targets, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {'seqA':self.seqA[idx], 'seqB':self.seqB[idx]}, self.targets[idx]\n",
    "    \n",
    "# Prepare dataset for training\n",
    "def prepare_data(train_df, test_df, target='interaction', batch_size=32, max_length=1000):\n",
    "    # Extract sequences and target values\n",
    "    train_seqA = train_df['seqA'].values\n",
    "    train_seqB = train_df['seqB'].values\n",
    "    y_train = train_df[target].values\n",
    "  \n",
    "    test_seqA = test_df['seqA'].values\n",
    "    test_seqB = test_df['seqB'].values\n",
    "    y_test = test_df[target].values\n",
    "  \n",
    "    # Create datasets with encoding\n",
    "    train_dataset = PiNUIDataset(train_seqA, train_seqB, y_train, max_length)\n",
    "    test_dataset = PiNUIDataset(test_seqA, test_seqB, y_test, max_length)\n",
    "  \n",
    "    # Create DataLoaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "  \n",
    "    return train_loader, test_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Loading Data<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Loading Data\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load dataset\n",
    "print(\"Loading Data...\")\n",
    "data_human = pd.read_csv(\"https://shiru-public.s3.us-west-2.amazonaws.com/PiNUI/PiNUI-human.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Preparing dataset<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Preparing dataset\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prepare dataset\n",
    "train_val_proteins, test_proteins = train_test_split(data_human, train_size=0.8)\n",
    "print(\"Preparing dataset...\")\n",
    "train_loader, test_loader = prepare_data(\n",
    "    train_val_proteins, test_proteins, target='interaction', batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MLP  \n",
    "class PiNUIMLP(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, hidden_dim, dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc3 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "        self.Dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, features_dict):\n",
    "        # Embedding for each seq\n",
    "        seqA = features_dict['seqA']\n",
    "        seqB = features_dict['seqB']\n",
    "\n",
    "        x = torch.stack([\n",
    "            seqA,\n",
    "            seqB\n",
    "        ], dim=1)\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.Dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        # x = self.sigmoid(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader,test_loader, criterion, optimizer, num_epochs, device='cuda', early_stopping=5):\n",
    "\n",
    "    model.to(device)\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    training_history = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_predictions = []\n",
    "        train_actuals = []\n",
    "\n",
    "        for batch_features, batch_targets in progress.track(train_loader, description=f\"Epoch {epoch + 1}\"):\n",
    "            \n",
    "            batch_features = {k:v.to(device, non_blocking=True) for k, v in batch_features.items()}\n",
    "            batch_targets = batch_targets.to(device, non_blocking=True).unsqueeze(1)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_features)\n",
    "            loss = criterion(outputs, batch_targets)\n",
    "            loss.backward()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            train_predictions.extend(outputs.detach().cpu().numpy())\n",
    "            train_actuals.extend(batch_targets.cpu().numpy())\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_predictions = []\n",
    "        val_actuals = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_features, batch_targets in test_loader:\n",
    "                batch_features = {k:v.to(device, non_blocking=True) for k, v in batch_features.items()}\n",
    "                batch_targets = batch_targets.to(device, non_blocking=True).unsqueeze(1)\n",
    "\n",
    "                outputs = model(batch_features)\n",
    "                v_loss = criterion(outputs, batch_targets)\n",
    "                                \n",
    "                val_loss += v_loss.item()\n",
    "                val_predictions.extend(outputs.cpu().numpy())\n",
    "                val_actuals.extend(outputs.cpu().numpy()) \n",
    "\n",
    "        print(\"Train Predictions:\", np.array(train_predictions).shape)\n",
    "        print(\"Train Actuals:\", np.array(train_actuals).shape)\n",
    "\n",
    "\n",
    "        # Metrics\n",
    "        train_loss /= len(train_loader)\n",
    "        val_loss /= len(test_loader)\n",
    "        # train_correlation = np.corrcoef(train_actuals, train_predictions)[0,1]\n",
    "        # val_correlation = np.corrcoef(val_actuals, val_predictions)[0,1]\n",
    "        \n",
    "        \n",
    "\n",
    "        # Append each epoch history\n",
    "        training_history.append({\n",
    "            'epoch': epoch + 1, \n",
    "            'train_loss': train_loss, \n",
    "            'val_loss': val_loss, \n",
    "            # 'train_correlation': train_correlation,\n",
    "            # 'val_correlation': val_correlation\n",
    "        })\n",
    "\n",
    "        print(f'\\n Epoch: {epoch + 1}/{num_epochs} ')\n",
    "        print(f'\\n Training loss: {train_loss:.4f}')\n",
    "        print(f'\\n Validation loss: {val_loss:.4f}')\n",
    "        # print(f'\\n Training loss: {train_loss:.4f}, Correlation: {train_correlation:4f}')\n",
    "        # print(f'\\n Validation loss: {val_loss:.4f}, Correlation: {val_correlation:.4f}')\n",
    "\n",
    "        # Early stopping \n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), \"best_model.pth\")\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        if patience_counter >= early_stopping:\n",
    "            print(f'Early stopping after {epoch + 1} epochs')\n",
    "            break\n",
    "    \n",
    "    return pd.DataFrame(training_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, device='cuda'):\n",
    "\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_features, batch_targets in test_loader:\n",
    "            batch_features = {k:v.to(device, non_blocking=True) for k, v in batch_features.items()}\n",
    "            batch_targets = batch_targets.to(device, non_blocking=True)\n",
    "\n",
    "            outputs = model(batch_features)\n",
    "\n",
    "            predictions.extend(outputs.cpu().numpy())\n",
    "            actuals.extend(batch_targets.cpu().numpy())\n",
    "    \n",
    "    return np.array(predictions), np.array(actuals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Intializing the Model<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Intializing the Model\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Setting the device<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Setting the device\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Using device: mps\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Using device: mps\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Training the model<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Training the model\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d48c8b50a43343849dcb61e1fcd3e5d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Train Predictions:\n",
       "<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">547960</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Train Predictions:\n",
       "\u001b[1m(\u001b[0m\u001b[1;36m547960\u001b[0m, \u001b[1;36m2\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Train Actuals:\n",
       "<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">547960</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Train Actuals:\n",
       "\u001b[1m(\u001b[0m\u001b[1;36m547960\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       " Epoch: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       " Epoch: \u001b[1;36m1\u001b[0m/\u001b[1;36m10\u001b[0m \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       " Training loss: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7364</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       " Training loss: \u001b[1;36m0.7364\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       " Validation loss: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7225</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       " Validation loss: \u001b[1;36m0.7225\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be1b3e6262ea440ea4df9694f38b54f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 26\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing device: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining the model...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 26\u001b[0m history \u001b[38;5;241m=\u001b[39m train_model(\n\u001b[1;32m     27\u001b[0m     model, \n\u001b[1;32m     28\u001b[0m     train_loader, \n\u001b[1;32m     29\u001b[0m     test_loader, \n\u001b[1;32m     30\u001b[0m     criterion, \n\u001b[1;32m     31\u001b[0m     optimizer, \n\u001b[1;32m     32\u001b[0m     num_epochs, \n\u001b[1;32m     33\u001b[0m     device, \n\u001b[1;32m     34\u001b[0m     early_stopping\n\u001b[1;32m     35\u001b[0m )\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluating the model...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     39\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_model.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "Cell \u001b[0;32mIn[13], line 23\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, test_loader, criterion, optimizer, num_epochs, device, early_stopping)\u001b[0m\n\u001b[1;32m     21\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     22\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(batch_features)\n\u001b[0;32m---> 23\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, batch_targets)\n\u001b[1;32m     24\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     26\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/shiru/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/shiru/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/shiru/lib/python3.13/site-packages/torch/nn/modules/loss.py:1295\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1294\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m-> 1295\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mcross_entropy(\n\u001b[1;32m   1296\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   1297\u001b[0m         target,\n\u001b[1;32m   1298\u001b[0m         weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight,\n\u001b[1;32m   1299\u001b[0m         ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mignore_index,\n\u001b[1;32m   1300\u001b[0m         reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreduction,\n\u001b[1;32m   1301\u001b[0m         label_smoothing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_smoothing,\n\u001b[1;32m   1302\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/shiru/lib/python3.13/site-packages/torch/nn/functional.py:3494\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3492\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3493\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3494\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39mcross_entropy_loss(\n\u001b[1;32m   3495\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   3496\u001b[0m     target,\n\u001b[1;32m   3497\u001b[0m     weight,\n\u001b[1;32m   3498\u001b[0m     _Reduction\u001b[38;5;241m.\u001b[39mget_enum(reduction),\n\u001b[1;32m   3499\u001b[0m     ignore_index,\n\u001b[1;32m   3500\u001b[0m     label_smoothing,\n\u001b[1;32m   3501\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Main\n",
    "print(\"Intializing the Model...\")\n",
    "model = PiNUIMLP(\n",
    "    input_dim=1000, \n",
    "    output_dim=1, \n",
    "    hidden_dim=256, \n",
    "    dropout=0.1,\n",
    ")\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr = 0.001)\n",
    "num_epochs = 10\n",
    "early_stopping = 5\n",
    "\n",
    "print(\"Setting the device...\")\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    if torch.mps.is_available():\n",
    "        device = 'mps'\n",
    "    else:\n",
    "        device = 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "print(\"Training the model...\")\n",
    "history = train_model(\n",
    "    model, \n",
    "    train_loader, \n",
    "    test_loader, \n",
    "    criterion, \n",
    "    optimizer, \n",
    "    num_epochs, \n",
    "    device, \n",
    "    early_stopping\n",
    ")\n",
    "\n",
    "\n",
    "print(\"Evaluating the model...\")\n",
    "model.load_state_dict(torch.load(\"best_model.pth\"))\n",
    "predictions, actuals = evaluate_model(model, train_loader, device)\n",
    "\n",
    "correlation = np.corrcoef(actuals, predictions)[0,1]\n",
    "print(f\"\\n Final correlation: {correlation:.4f}\")\n",
    "\n",
    "# Saving the results\n",
    "results = {\n",
    "    'history': history, \n",
    "    'predictions': predictions, \n",
    "    'actuals': actuals   \n",
    "}\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "with open(\"results/results.pkl\", \"wb\") as f:\n",
    "    pickle.dump(results, f)\n",
    "print(\"Results saved in results directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shiru",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
