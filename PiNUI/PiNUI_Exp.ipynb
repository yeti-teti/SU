{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import scipy as sp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_human = pd.read_csv(\"https://shiru-public.s3.us-west-2.amazonaws.com/PiNUI/PiNUI-human.csv\")\n",
    "data_yeast = pd.read_csv(\"https://shiru-public.s3.us-west-2.amazonaws.com/PiNUI/PiNUI-yeast.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684951\n",
      "------------------------------\n",
      "                                                seqA  \\\n",
      "0  MKRRASDRGAGETSARAKALGSGISGNNAKRAGPFILGPRLGNSPV...   \n",
      "1  MEAPSGSEPGGDGAGDCAHPDPRAPGAAAPSSGPGPCAAARESERQ...   \n",
      "2  MDQNSVPEKAQNEADTNNADRFFRSHSSPPHHRPGHSRALHHYELH...   \n",
      "3  MFADLDYDIEEDKLGIPTVPGKVTLQKDAQNLIGISIGGGAQYCPC...   \n",
      "4  MAEGNHRKKPLKVLESLGKDFLTGVLDNLVEQNVLNWKEEEKKKYY...   \n",
      "\n",
      "                                                seqB  interaction  \n",
      "0  MAASAARGAAALRRSINQPVAFVRRIPWTAASSQLKEHFAQFGHVR...            1  \n",
      "1  MKLFHTADWHLGKLVHGVYMTEDQKIVLDQFVQAVEEEKPDAVIIA...            1  \n",
      "2  MTHCCSPCCQPTCCRTTCWQPTTVTTCSSTPCCQPSCCVSSCCQPC...            1  \n",
      "3  MARTLRPSPLCPGGGKAQLSSASLLGAGLLLQPPTPPPLLLLLFPL...            1  \n",
      "4  MASADSRRVADGGGAGGTFQPYLDTLRQELQQTDPTLLSVVVAVLA...            1  \n",
      "------------------------------\n",
      "         interaction\n",
      "count  684951.000000\n",
      "mean        0.333333\n",
      "std         0.471405\n",
      "min         0.000000\n",
      "25%         0.000000\n",
      "50%         0.000000\n",
      "75%         1.000000\n",
      "max         1.000000\n",
      "------------------------------\n",
      "30263\n",
      "30260\n"
     ]
    }
   ],
   "source": [
    "print(len(data_human))\n",
    "print('---'*10)\n",
    "print(data_human.head())\n",
    "print('---'*10)\n",
    "print(data_human.describe())\n",
    "print('---'*10)\n",
    "print(len(data_human['seqA'].unique()))\n",
    "print(len(data_human['seqB'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "connections = {\n",
    "    (row.seqA, row.seqB): row.interaction\n",
    "    for row in data_human.itertuples(index=False) if row.interaction\n",
    "}\n",
    "\n",
    "\n",
    "connections_network = defaultdict(list) \n",
    "\n",
    "for row in data_human.itertuples(index=False):\n",
    "    if row.interaction:\n",
    "        if row.seqB not in connections_network[row.seqA]:\n",
    "            connections_network[row.seqA].append(row.seqB)\n",
    "\n",
    "\n",
    "network_pd = pd.DataFrame(dict([(k, pd.Series(v)) for k, v in connections_network.items()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159111\n",
      "------------------------------\n",
      "                                                seqA  \\\n",
      "0  MVKETKFYDILGVPVTATDVEIKKAYRKCALKYHPDKNPSEEAAEK...   \n",
      "1  MSAPAANGEVPTFKLVLVGDGGTGKTTFVKRHLTGEFEKKYIATIG...   \n",
      "2  MFFSKVMLTRRILVRGLATAKSSAPKLTDVLIVGGGPAGLTLAASI...   \n",
      "3  MSHSGAAIFEKVSGIIAINEDVSPAELTWRSTDGDKVHTVVLSTID...   \n",
      "4  MAETSLLEAGASAASTAAALENLQVEASCSVCLEYLKEPVIIECGH...   \n",
      "\n",
      "                                                seqB  interaction  \n",
      "0  MYYGISQFSEAYNKILRNSSSHSSCQLVIFVSCLNIDALCATKMLS...            1  \n",
      "1  MVKRTVATNGDASGAHRAKKMSKTHASHIINAQEDYKHMYLSVQPL...            1  \n",
      "2  MIPKLYIHLILSLLLLPLILAQDYYAILEIDKDATEKEIKSAYRQL...            1  \n",
      "3  MAEGVFQGAIGIDLGTTYSCVATYESSVEIIANEQGNRVTPSFVAF...            1  \n",
      "4  MEKKHVTVQIQSAPPSYIKLEANEKFVYITSTMNGLSYQIAAIVSY...            1  \n",
      "------------------------------\n",
      "         interaction\n",
      "count  159111.000000\n",
      "mean        0.333333\n",
      "std         0.471406\n",
      "min         0.000000\n",
      "25%         0.000000\n",
      "50%         0.000000\n",
      "75%         1.000000\n",
      "max         1.000000\n",
      "------------------------------\n",
      "6654\n",
      "6655\n"
     ]
    }
   ],
   "source": [
    "print(len(data_yeast))\n",
    "print('---'*10)\n",
    "print(data_yeast.head())\n",
    "print('---'*10)\n",
    "print(data_yeast.describe())\n",
    "print('---'*10)\n",
    "print(len(data_yeast['seqA'].unique()))\n",
    "print(len(data_yeast['seqB'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Prep "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sequence(seq, max_length=1000):\n",
    "    # Define a mapping for common amino acids\n",
    "    amino_acids = \"ACDEFGHIKLMNPQRSTVWY\"\n",
    "    aa_to_int = {aa: i + 1 for i, aa in enumerate(amino_acids)}  # reserve 0 for padding\n",
    "\n",
    "    # Convert each amino acid in the sequence to its corresponding integer\n",
    "    encoded = [aa_to_int.get(aa, 0) for aa in seq]  # default to 0 if amino acid not found\n",
    "\n",
    "    # Pad or truncate the sequence to max_length\n",
    "    if len(encoded) < max_length:\n",
    "        encoded += [0] * (max_length - len(encoded))\n",
    "    else:\n",
    "        encoded = encoded[:max_length]\n",
    "    return encoded\n",
    "\n",
    "\n",
    "class PiNUIDataset(Dataset):\n",
    "    def __init__(self, seqA, seqB, targets, max_length=1000):\n",
    "        # Encode sequences from strings to numerical lists\n",
    "        self.seqA = [encode_sequence(seq, max_length) for seq in seqA]\n",
    "        self.seqB = [encode_sequence(seq, max_length) for seq in seqB]\n",
    "        self.targets = targets\n",
    "\n",
    "        # Convert the numerical lists and targets to tensors\n",
    "        self.seqA = torch.tensor(self.seqA, dtype=torch.float32)\n",
    "        self.seqB = torch.tensor(self.seqB, dtype=torch.float32)\n",
    "        self.targets = torch.tensor(self.targets, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Return a tuple for clarity\n",
    "        return (self.seqA[idx], self.seqB[idx]), self.targets[idx]\n",
    "    \n",
    "# Prepare dataset for training\n",
    "def prepare_data(train_df, test_df, target='interaction', batch_size=32, max_length=1000):\n",
    "    # Extract sequences and target values\n",
    "    train_seqA = train_df['seqA'].values\n",
    "    train_seqB = train_df['seqB'].values\n",
    "    y_train = train_df[target].values\n",
    "  \n",
    "    test_seqA = test_df['seqA'].values\n",
    "    test_seqB = test_df['seqB'].values\n",
    "    y_test = test_df[target].values\n",
    "  \n",
    "    # Create datasets with encoding\n",
    "    train_dataset = PiNUIDataset(train_seqA, train_seqB, y_train, max_length)\n",
    "    test_dataset = PiNUIDataset(test_seqA, test_seqB, y_test, max_length)\n",
    "  \n",
    "    # Create DataLoaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "  \n",
    "    return train_loader, test_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data...\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "print(\"Loading Data...\")\n",
    "data_human = pd.read_csv(\"https://shiru-public.s3.us-west-2.amazonaws.com/PiNUI/PiNUI-human.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing dataset\n",
      "Preparing dataset\n"
     ]
    }
   ],
   "source": [
    "train_val_proteins, test_proteins = train_test_split(data_human, train_size=0.8)\n",
    "\n",
    "# Prepare dataset\n",
    "print(\"Preparing dataset\")\n",
    "train_loader, test_loader = prepare_data(\n",
    "    train_val_proteins, test_proteins, target='interaction', batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[11., 16., 13.,  ...,  0.,  0.,  0.],\n",
      "        [11.,  1.,  1.,  ...,  0.,  0.,  0.],\n",
      "        [11., 14., 15.,  ...,  0.,  0.,  0.],\n",
      "        ...,\n",
      "        [11.,  1., 17.,  ...,  0.,  0.,  0.],\n",
      "        [11.,  1., 16.,  ...,  0.,  0.,  0.],\n",
      "        [11.,  1., 13.,  ...,  0.,  0.,  0.]]), tensor([[11.,  1., 13.,  ..., 18.,  9.,  8.],\n",
      "        [11., 16.,  9.,  ...,  0.,  0.,  0.],\n",
      "        [11., 16.,  9.,  ...,  0.,  0.,  0.],\n",
      "        ...,\n",
      "        [11., 17., 11.,  ...,  0.,  0.,  0.],\n",
      "        [11.,  3., 16.,  ...,  0.,  0.,  0.],\n",
      "        [11., 12., 18.,  ..., 14., 14.,  6.]])]\n",
      "tensor([0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0.,\n",
      "        0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0.])\n"
     ]
    }
   ],
   "source": [
    "data_iter = iter(train_loader)\n",
    "first_batch_data, first_batch_labels = next(data_iter)\n",
    "print(first_batch_data)\n",
    "print(first_batch_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shiru",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
