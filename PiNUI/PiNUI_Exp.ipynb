{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import scipy as sp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from rich import print, progress\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Prep "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sequence(seq, max_length=1000):\n",
    "    # Define a mapping for common amino acids\n",
    "    amino_acids = \"ACDEFGHIKLMNPQRSTVWY\"\n",
    "    aa_to_int = {aa: i + 1 for i, aa in enumerate(amino_acids)}  # reserve 0 for padding\n",
    "\n",
    "    # Convert each amino acid in the sequence to its corresponding integer\n",
    "    encoded = [aa_to_int.get(aa, 0) for aa in seq]  # default to 0 if amino acid not found\n",
    "\n",
    "    # Pad or truncate the sequence to max_length\n",
    "    if len(encoded) < max_length:\n",
    "        encoded += [0] * (max_length - len(encoded))\n",
    "    else:\n",
    "        encoded = encoded[:max_length]\n",
    "    return encoded\n",
    "\n",
    "\n",
    "class PiNUIDataset(Dataset):\n",
    "    def __init__(self, seqA, seqB, targets, max_length=1000):\n",
    "        # Encode sequences from strings to numerical lists\n",
    "        self.seqA = [encode_sequence(seq, max_length) for seq in seqA]\n",
    "        self.seqB = [encode_sequence(seq, max_length) for seq in seqB]\n",
    "        self.targets = targets\n",
    "\n",
    "        # Convert the numerical lists and targets to tensors\n",
    "        self.seqA = torch.tensor(self.seqA, dtype=torch.float32)\n",
    "        self.seqB = torch.tensor(self.seqB, dtype=torch.float32)\n",
    "        self.targets = torch.tensor(self.targets, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {'seqA':self.seqA[idx], 'seqB':self.seqB[idx]}, self.targets[idx]\n",
    "    \n",
    "# Prepare dataset for training\n",
    "def prepare_data(train_df, test_df, target='interaction', batch_size=32, max_length=1000):\n",
    "    # Extract sequences and target values\n",
    "    train_seqA = train_df['seqA'].values\n",
    "    train_seqB = train_df['seqB'].values\n",
    "    y_train = train_df[target].values\n",
    "  \n",
    "    test_seqA = test_df['seqA'].values\n",
    "    test_seqB = test_df['seqB'].values\n",
    "    y_test = test_df[target].values\n",
    "  \n",
    "    # Create datasets with encoding\n",
    "    train_dataset = PiNUIDataset(train_seqA, train_seqB, y_train, max_length)\n",
    "    test_dataset = PiNUIDataset(test_seqA, test_seqB, y_test, max_length)\n",
    "  \n",
    "    # Create DataLoaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "  \n",
    "    return train_loader, test_loader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MLP  \n",
    "class PiNUIMLP(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, hidden_dim, dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc3 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "        self.Dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, features_dict):\n",
    "        # Embedding for each seq\n",
    "        seqA = features_dict['seqA']\n",
    "        seqB = features_dict['seqB']\n",
    "\n",
    "        x = torch.stack([\n",
    "            seqA,\n",
    "            seqB\n",
    "        ], dim=1)\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.Dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.sigmoid(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader,test_loader, criterion, optimizer, num_epochs, device='cuda', early_stopping='5'):\n",
    "\n",
    "    model.to(device)\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    training_history = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_predictions = []\n",
    "        train_actuals = []\n",
    "\n",
    "        for batch_features, batch_targets in progress.track(train_loader, description=f\"Epoch {epoch + 1}\"):\n",
    "            \n",
    "            batch_features = {k:v.to(device, non_blocking=True) for k, v in batch_features.items()}\n",
    "            batch_targets = batch_targets.to(device, non_blocking=True).unsqueeze(-1)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_features)\n",
    "            loss = criterion(outputs, batch_targets)\n",
    "            loss.backward()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            train_predictions.extend(outputs.detach().cpu().numpy())\n",
    "            train_actuals.extend(batch_targets.cpu().numpy())\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_predictions = []\n",
    "        val_actuals = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_features, batch_targets in test_loader:\n",
    "                batch_features = {k:v.to(device, non_blocking=True) for k, v in batch_features.items()}\n",
    "                batch_targets = batch_targets.to(device, non_blocking=True)\n",
    "\n",
    "                outputs = model(batch_targets)\n",
    "                v_loss = criterion(outputs, batch_targets)\n",
    "                                \n",
    "                val_loss += v_loss.item()\n",
    "                val_predictions.extend(outputs.cpu().numpy())\n",
    "                val_actuals.extend(outputs.cpu().numpy())\n",
    "\n",
    "        # Metrics\n",
    "        train_loss /= len(train_loader)\n",
    "        val_loss /= len(test_loader)\n",
    "        train_correlation = np.corrcoef(train_actuals, train_predictions)[0,1]\n",
    "        val_correlation = np.corrcoef(val_actuals, val_predictions)[0,1]\n",
    "        \n",
    "        # Append each epoch history\n",
    "        training_history.append({\n",
    "            'epoch': epoch + 1, \n",
    "            'train_loss': train_loss, \n",
    "            'val_loss': val_loss, \n",
    "            'train_correlation': train_correlation,\n",
    "            'val_correlation': val_correlation\n",
    "        })\n",
    "\n",
    "        print(f'\\n Epoch: {epoch + 1}/{num_epochs} ')\n",
    "        print(f'\\n Training loss: {train_loss:.4f}, Correlation: {train_correlation:4f}')\n",
    "        print(f'\\n Validation loss: {val_loss:.4f}, Correlation: {val_correlation:.4f}')\n",
    "\n",
    "        # Early stopping \n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), \"best_model.pth\")\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        if patience_counter >= early_stopping:\n",
    "            print(f'Early stopping after {epoch + 1} epochs')\n",
    "            break\n",
    "    \n",
    "    return pd.DataFrame(training_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, device='cuda'):\n",
    "\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_features, batch_targets in test_loader:\n",
    "            batch_features = {k:v.to(device, non_blocking=True) for k, v in batch_features.items()}\n",
    "            batch_targets = batch_targets.to(device, non_blocking=True)\n",
    "\n",
    "            outputs = model(batch_features)\n",
    "\n",
    "            predictions.extend(outputs.cpu().numpy())\n",
    "            actuals.extend(batch_targets.cpu().numpy())\n",
    "    \n",
    "    return np.array(predictions), np.array(actuals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Loading Data<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Loading Data\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load dataset\n",
    "print(\"Loading Data...\")\n",
    "data_human = pd.read_csv(\"https://shiru-public.s3.us-west-2.amazonaws.com/PiNUI/PiNUI-human.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Preparing dataset<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Preparing dataset\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_6/7t87hdks683bh7l07gtby3740000gn/T/ipykernel_22211/2782287716.py:25: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.seqA = torch.tensor(self.seqA, dtype=torch.float32)\n",
      "/var/folders/_6/7t87hdks683bh7l07gtby3740000gn/T/ipykernel_22211/2782287716.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.seqB = torch.tensor(self.seqB, dtype=torch.float32)\n",
      "/var/folders/_6/7t87hdks683bh7l07gtby3740000gn/T/ipykernel_22211/2782287716.py:27: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.targets = torch.tensor(self.targets, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "# Prepare dataset\n",
    "train_val_proteins, test_proteins = train_test_split(data_human, train_size=0.8)\n",
    "print(\"Preparing dataset...\")\n",
    "train_loader, test_loader = prepare_data(\n",
    "    train_val_proteins, test_proteins, target='interaction', batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'seqA'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span>.,  <span style=\"color: #808000; text-decoration-color: #808000\">...</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.<span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>.,  <span style=\"color: #808000; text-decoration-color: #808000\">...</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>.<span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>.,  <span style=\"color: #808000; text-decoration-color: #808000\">...</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.<span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">...</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17</span>.,  <span style=\"color: #808000; text-decoration-color: #808000\">...</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.<span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>.,  <span style=\"color: #808000; text-decoration-color: #808000\">...</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.<span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span>.,  <span style=\"color: #808000; text-decoration-color: #808000\">...</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.<span style=\"font-weight: bold\">]])</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'seqB'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>.,  <span style=\"color: #808000; text-decoration-color: #808000\">...</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.<span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span>.,  <span style=\"color: #808000; text-decoration-color: #808000\">...</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.<span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span>.,  <span style=\"color: #808000; text-decoration-color: #808000\">...</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.<span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">...</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>.,  <span style=\"color: #808000; text-decoration-color: #808000\">...</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.<span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>.,  <span style=\"color: #808000; text-decoration-color: #808000\">...</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.<span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span>.,  <span style=\"color: #808000; text-decoration-color: #808000\">...</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span>.<span style=\"font-weight: bold\">]])</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'seqA'\u001b[0m: \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m11\u001b[0m., \u001b[1;36m11\u001b[0m., \u001b[1;36m13\u001b[0m.,  \u001b[33m...\u001b[0m,  \u001b[1;36m0\u001b[0m.,  \u001b[1;36m0\u001b[0m.,  \u001b[1;36m0\u001b[0m.\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m11\u001b[0m.,  \u001b[1;36m1\u001b[0m.,  \u001b[1;36m4\u001b[0m.,  \u001b[33m...\u001b[0m,  \u001b[1;36m9\u001b[0m., \u001b[1;36m17\u001b[0m.,  \u001b[1;36m4\u001b[0m.\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m11\u001b[0m.,  \u001b[1;36m1\u001b[0m.,  \u001b[1;36m1\u001b[0m.,  \u001b[33m...\u001b[0m,  \u001b[1;36m0\u001b[0m.,  \u001b[1;36m0\u001b[0m.,  \u001b[1;36m0\u001b[0m.\u001b[1m]\u001b[0m,\n",
       "        \u001b[33m...\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m11\u001b[0m., \u001b[1;36m17\u001b[0m., \u001b[1;36m17\u001b[0m.,  \u001b[33m...\u001b[0m,  \u001b[1;36m0\u001b[0m.,  \u001b[1;36m0\u001b[0m.,  \u001b[1;36m0\u001b[0m.\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m11\u001b[0m.,  \u001b[1;36m1\u001b[0m.,  \u001b[1;36m3\u001b[0m.,  \u001b[33m...\u001b[0m,  \u001b[1;36m0\u001b[0m.,  \u001b[1;36m0\u001b[0m.,  \u001b[1;36m0\u001b[0m.\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m11\u001b[0m.,  \u001b[1;36m4\u001b[0m.,  \u001b[1;36m9\u001b[0m.,  \u001b[33m...\u001b[0m,  \u001b[1;36m0\u001b[0m.,  \u001b[1;36m0\u001b[0m.,  \u001b[1;36m0\u001b[0m.\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[32m'seqB'\u001b[0m: \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m11\u001b[0m., \u001b[1;36m17\u001b[0m.,  \u001b[1;36m4\u001b[0m.,  \u001b[33m...\u001b[0m,  \u001b[1;36m0\u001b[0m.,  \u001b[1;36m0\u001b[0m.,  \u001b[1;36m0\u001b[0m.\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m11\u001b[0m., \u001b[1;36m19\u001b[0m., \u001b[1;36m16\u001b[0m.,  \u001b[33m...\u001b[0m,  \u001b[1;36m0\u001b[0m.,  \u001b[1;36m0\u001b[0m.,  \u001b[1;36m0\u001b[0m.\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m11\u001b[0m.,  \u001b[1;36m3\u001b[0m.,  \u001b[1;36m9\u001b[0m.,  \u001b[33m...\u001b[0m,  \u001b[1;36m0\u001b[0m.,  \u001b[1;36m0\u001b[0m.,  \u001b[1;36m0\u001b[0m.\u001b[1m]\u001b[0m,\n",
       "        \u001b[33m...\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m11\u001b[0m., \u001b[1;36m16\u001b[0m.,  \u001b[1;36m6\u001b[0m.,  \u001b[33m...\u001b[0m,  \u001b[1;36m0\u001b[0m.,  \u001b[1;36m0\u001b[0m.,  \u001b[1;36m0\u001b[0m.\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m20\u001b[0m.,  \u001b[1;36m6\u001b[0m.,  \u001b[1;36m6\u001b[0m.,  \u001b[33m...\u001b[0m,  \u001b[1;36m0\u001b[0m.,  \u001b[1;36m0\u001b[0m.,  \u001b[1;36m0\u001b[0m.\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m11\u001b[0m., \u001b[1;36m13\u001b[0m., \u001b[1;36m16\u001b[0m.,  \u001b[33m...\u001b[0m,  \u001b[1;36m2\u001b[0m.,  \u001b[1;36m4\u001b[0m., \u001b[1;36m16\u001b[0m.\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for batch_feature, batch_label in train_loader:\n",
    "    print(batch_feature)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Intializing the Model<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Intializing the Model\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Setting the device<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Setting the device\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Using device: mps\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Using device: mps\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Training the model<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Training the model\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/opt/anaconda3/envs/shiru/lib/python3.13/site-packages/rich/live.py:231: UserWarning: install \"ipywidgets\" for \n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/opt/anaconda3/envs/shiru/lib/python3.13/site-packages/rich/live.py:231: UserWarning: install \"ipywidgets\" for \n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Main\n",
    "print(\"Intializing the Model...\")\n",
    "model = PiNUIMLP(\n",
    "    input_dim=1000, \n",
    "    output_dim=1, \n",
    "    hidden_dim=256, \n",
    "    dropout=0.1,\n",
    ")\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr = 0.001)\n",
    "num_epochs = 10\n",
    "early_stopping = 5\n",
    "\n",
    "print(\"Setting the device...\")\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    if torch.mps.is_available():\n",
    "        device = 'mps'\n",
    "    else:\n",
    "        device = 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "print(\"Training the model...\")\n",
    "history = train_model(\n",
    "    model, \n",
    "    train_loader, \n",
    "    test_loader, \n",
    "    criterion, \n",
    "    optimizer, \n",
    "    num_epochs, \n",
    "    device, \n",
    "    early_stopping\n",
    ")\n",
    "\n",
    "\n",
    "print(\"Evaluating the model...\")\n",
    "model.load_state_dict(torch.load(\"best_model.pth\"))\n",
    "predictions, actuals = evaluate_model(model, train_loader, device)\n",
    "\n",
    "correlation = np.corrcoef(actuals, predictions)[0,1]\n",
    "print(\"\\n Final correlation: {correlation:.4f}\")\n",
    "\n",
    "# Saving the results\n",
    "results = {\n",
    "    'history': history, \n",
    "    'predictions': predictions, \n",
    "    'actuals': actuals   \n",
    "}\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "with open(\"results/resuls.pkl\", \"wb\") as f:\n",
    "    pickle.dump(results, f)\n",
    "print(\"Results saved in results directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shiru",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
