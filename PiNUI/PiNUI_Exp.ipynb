{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import scipy as sp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from rich import print, progress\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Prep "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sequence(seq, max_length=1000):\n",
    "    # Define a mapping for common amino acids\n",
    "    amino_acids = \"ACDEFGHIKLMNPQRSTVWY\"\n",
    "    aa_to_int = {aa: i + 1 for i, aa in enumerate(amino_acids)}  # reserve 0 for padding\n",
    "\n",
    "    # Convert each amino acid in the sequence to its corresponding integer\n",
    "    encoded = [aa_to_int.get(aa, 0) for aa in seq]  # default to 0 if amino acid not found\n",
    "\n",
    "    # Pad or truncate the sequence to max_length\n",
    "    if len(encoded) < max_length:\n",
    "        encoded += [0] * (max_length - len(encoded))\n",
    "    else:\n",
    "        encoded = encoded[:max_length]\n",
    "    return encoded\n",
    "\n",
    "\n",
    "class PiNUIDataset(Dataset):\n",
    "    def __init__(self, seqA, seqB, targets, max_length=1000):\n",
    "        # Encode sequences from strings to numerical lists\n",
    "        self.seqA = [encode_sequence(seq, max_length) for seq in seqA]\n",
    "        self.seqB = [encode_sequence(seq, max_length) for seq in seqB]\n",
    "        self.targets = targets\n",
    "\n",
    "        # Convert the numerical lists and targets to tensors\n",
    "        self.seqA = torch.tensor(self.seqA, dtype=torch.float32)\n",
    "        self.seqB = torch.tensor(self.seqB, dtype=torch.float32)\n",
    "        self.targets = torch.tensor(self.targets, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {'seqA':self.seqA[idx], 'seqB':self.seqB[idx]}, self.targets[idx]\n",
    "    \n",
    "# Prepare dataset for training\n",
    "def prepare_data(train_df, test_df, target='interaction', batch_size=32, max_length=1000):\n",
    "    # Extract sequences and target values\n",
    "    train_seqA = train_df['seqA'].values\n",
    "    train_seqB = train_df['seqB'].values\n",
    "    y_train = train_df[target].values\n",
    "  \n",
    "    test_seqA = test_df['seqA'].values\n",
    "    test_seqB = test_df['seqB'].values\n",
    "    y_test = test_df[target].values\n",
    "  \n",
    "    # Create datasets with encoding\n",
    "    train_dataset = PiNUIDataset(train_seqA, train_seqB, y_train, max_length)\n",
    "    test_dataset = PiNUIDataset(test_seqA, test_seqB, y_test, max_length)\n",
    "  \n",
    "    # Create DataLoaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "  \n",
    "    return train_loader, test_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Loading Data<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Loading Data\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load dataset\n",
    "print(\"Loading Data...\")\n",
    "data_human = pd.read_csv(\"https://shiru-public.s3.us-west-2.amazonaws.com/PiNUI/PiNUI-human.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Preparing dataset<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Preparing dataset\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prepare dataset\n",
    "train_val_proteins, test_proteins = train_test_split(data_human, train_size=0.8)\n",
    "print(\"Preparing dataset...\")\n",
    "train_loader, test_loader = prepare_data(\n",
    "    train_val_proteins, test_proteins, target='interaction', batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MLP  \n",
    "class PiNUIMLP(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, hidden_dim, dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc3 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "        self.Dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, features_dict):\n",
    "        # Embedding for each seq\n",
    "        seqA = features_dict['seqA']\n",
    "        seqB = features_dict['seqB']\n",
    "\n",
    "        x = torch.stack([\n",
    "            seqA,\n",
    "            seqB\n",
    "        ], dim=1)\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.Dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        # x = self.sigmoid(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader,test_loader, criterion, optimizer, num_epochs, device='cuda', early_stopping=5):\n",
    "\n",
    "    model.to(device)\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    training_history = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_predictions = []\n",
    "        train_actuals = []\n",
    "\n",
    "        for batch_features, batch_targets in progress.track(train_loader, description=f\"Epoch {epoch + 1}\"):\n",
    "            \n",
    "            batch_features = {k:v.to(device, non_blocking=True) for k, v in batch_features.items()}\n",
    "            batch_targets = batch_targets.to(device, non_blocking=True).unsqueeze(1)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_features)\n",
    "            loss = criterion(outputs, batch_targets)\n",
    "            loss.backward()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            train_predictions.extend(outputs.detach().cpu().numpy())\n",
    "            train_actuals.extend(batch_targets.cpu().numpy())\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_predictions = []\n",
    "        val_actuals = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_features, batch_targets in test_loader:\n",
    "                batch_features = {k:v.to(device, non_blocking=True) for k, v in batch_features.items()}\n",
    "                batch_targets = batch_targets.to(device, non_blocking=True).unsqueeze(1)\n",
    "\n",
    "                outputs = model(batch_features)\n",
    "                v_loss = criterion(outputs, batch_targets)\n",
    "                                \n",
    "                val_loss += v_loss.item()\n",
    "                val_predictions.extend(outputs.cpu().numpy())\n",
    "                val_actuals.extend(outputs.cpu().numpy()) \n",
    "\n",
    "        # print(\"Train Predictions:\", np.array(train_predictions).shape)\n",
    "        # print(\"Train Actuals:\", np.array(train_actuals).shape)\n",
    "\n",
    "\n",
    "        # Metrics\n",
    "        train_loss /= len(train_loader)\n",
    "        val_loss /= len(test_loader)\n",
    "        # train_correlation = np.corrcoef(train_actuals, train_predictions)[0,1]\n",
    "        # val_correlation = np.corrcoef(val_actuals, val_predictions)[0,1]\n",
    "        \n",
    "        \n",
    "\n",
    "        # Append each epoch history\n",
    "        training_history.append({\n",
    "            'epoch': epoch + 1, \n",
    "            'train_loss': train_loss, \n",
    "            'val_loss': val_loss, \n",
    "            # 'train_correlation': train_correlation,\n",
    "            # 'val_correlation': val_correlation\n",
    "        })\n",
    "\n",
    "        print(f'\\n Epoch: {epoch + 1}/{num_epochs} ')\n",
    "        print(f'\\n Training loss: {train_loss:.4f}')\n",
    "        print(f'\\n Validation loss: {val_loss:.4f}')\n",
    "        # print(f'\\n Training loss: {train_loss:.4f}, Correlation: {train_correlation:4f}')\n",
    "        # print(f'\\n Validation loss: {val_loss:.4f}, Correlation: {val_correlation:.4f}')\n",
    "\n",
    "        # Early stopping \n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), \"best_model.pth\")\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        if patience_counter >= early_stopping:\n",
    "            print(f'Early stopping after {epoch + 1} epochs')\n",
    "            break\n",
    "    \n",
    "    return pd.DataFrame(training_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, device='cuda'):\n",
    "\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_features, batch_targets in test_loader:\n",
    "            batch_features = {k:v.to(device, non_blocking=True) for k, v in batch_features.items()}\n",
    "            batch_targets = batch_targets.to(device, non_blocking=True)\n",
    "\n",
    "            outputs = model(batch_features)\n",
    "\n",
    "            predictions.extend(outputs.cpu().numpy())\n",
    "            actuals.extend(batch_targets.cpu().numpy())\n",
    "    \n",
    "    return np.array(predictions), np.array(actuals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Intializing the Model<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Intializing the Model\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Setting the device<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Setting the device\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Using device: mps\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Using device: mps\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Training the model<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Training the model\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9d614e414cc4301b8a7a78bcbec7496",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       " Epoch: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       " Epoch: \u001b[1;36m1\u001b[0m/\u001b[1;36m10\u001b[0m \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       " Training loss: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7602</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       " Training loss: \u001b[1;36m0.7602\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       " Validation loss: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7115</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       " Validation loss: \u001b[1;36m0.7115\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "382cb90f9e8548478d8be09d03d79380",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       " Epoch: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       " Epoch: \u001b[1;36m2\u001b[0m/\u001b[1;36m10\u001b[0m \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       " Training loss: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7602</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       " Training loss: \u001b[1;36m0.7602\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       " Validation loss: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7447</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       " Validation loss: \u001b[1;36m0.7447\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99220d01d04f4d68a0fbb4ad835ed4b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       " Epoch: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       " Epoch: \u001b[1;36m3\u001b[0m/\u001b[1;36m10\u001b[0m \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       " Training loss: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7600</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       " Training loss: \u001b[1;36m0.7600\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       " Validation loss: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7295</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       " Validation loss: \u001b[1;36m0.7295\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dd74b06986d480f925794e18039209b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       " Epoch: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       " Epoch: \u001b[1;36m4\u001b[0m/\u001b[1;36m10\u001b[0m \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       " Training loss: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7600</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       " Training loss: \u001b[1;36m0.7600\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       " Validation loss: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7243</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       " Validation loss: \u001b[1;36m0.7243\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad8ece15949141ddadc5b8ccb5907e5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       " Epoch: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       " Epoch: \u001b[1;36m5\u001b[0m/\u001b[1;36m10\u001b[0m \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       " Training loss: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7602</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       " Training loss: \u001b[1;36m0.7602\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       " Validation loss: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7197</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       " Validation loss: \u001b[1;36m0.7197\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d298e6aa8b5428493405abd3b289e92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       " Epoch: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       " Epoch: \u001b[1;36m6\u001b[0m/\u001b[1;36m10\u001b[0m \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       " Training loss: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7602</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       " Training loss: \u001b[1;36m0.7602\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       " Validation loss: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7217</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       " Validation loss: \u001b[1;36m0.7217\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Early stopping after <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span> epochs\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Early stopping after \u001b[1;36m6\u001b[0m epochs\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluating the model<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluating the model\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "y has more than 2 dimensions",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 42\u001b[0m\n\u001b[1;32m     39\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_model.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     40\u001b[0m predictions, actuals \u001b[38;5;241m=\u001b[39m evaluate_model(model, train_loader, device)\n\u001b[0;32m---> 42\u001b[0m correlation \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcorrcoef(actuals, predictions)[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m Final correlation: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcorrelation\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Saving the results\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/shiru/lib/python3.13/site-packages/numpy/lib/_function_base_impl.py:3037\u001b[0m, in \u001b[0;36mcorrcoef\u001b[0;34m(x, y, rowvar, bias, ddof, dtype)\u001b[0m\n\u001b[1;32m   3033\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39m_NoValue \u001b[38;5;129;01mor\u001b[39;00m ddof \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39m_NoValue:\n\u001b[1;32m   3034\u001b[0m     \u001b[38;5;66;03m# 2015-03-15, 1.10\u001b[39;00m\n\u001b[1;32m   3035\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbias and ddof have no effect and are deprecated\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   3036\u001b[0m                   \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m-> 3037\u001b[0m c \u001b[38;5;241m=\u001b[39m cov(x, y, rowvar, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m   3038\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   3039\u001b[0m     d \u001b[38;5;241m=\u001b[39m diag(c)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/shiru/lib/python3.13/site-packages/numpy/lib/_function_base_impl.py:2812\u001b[0m, in \u001b[0;36mcov\u001b[0;34m(m, y, rowvar, bias, ddof, fweights, aweights, dtype)\u001b[0m\n\u001b[1;32m   2810\u001b[0m     y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(y)\n\u001b[1;32m   2811\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m-> 2812\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my has more than 2 dimensions\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2814\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2815\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: y has more than 2 dimensions"
     ]
    }
   ],
   "source": [
    "# Main\n",
    "print(\"Intializing the Model...\")\n",
    "model = PiNUIMLP(\n",
    "    input_dim=1000, \n",
    "    output_dim=1, \n",
    "    hidden_dim=256, \n",
    "    dropout=0.1,\n",
    ")\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr = 0.001)\n",
    "num_epochs = 10\n",
    "early_stopping = 5\n",
    "\n",
    "print(\"Setting the device...\")\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    if torch.mps.is_available():\n",
    "        device = 'mps'\n",
    "    else:\n",
    "        device = 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "print(\"Training the model...\")\n",
    "history = train_model(\n",
    "    model, \n",
    "    train_loader, \n",
    "    test_loader, \n",
    "    criterion, \n",
    "    optimizer, \n",
    "    num_epochs, \n",
    "    device, \n",
    "    early_stopping\n",
    ")\n",
    "\n",
    "\n",
    "print(\"Evaluating the model...\")\n",
    "model.load_state_dict(torch.load(\"best_model.pth\"))\n",
    "predictions, actuals = evaluate_model(model, train_loader, device)\n",
    "\n",
    "# correlation = np.corrcoef(actuals, predictions)[0,1]\n",
    "# print(f\"\\n Final correlation: {correlation:.4f}\")\n",
    "\n",
    "# Saving the results\n",
    "results = {\n",
    "    'history': history, \n",
    "    'predictions': predictions, \n",
    "    'actuals': actuals   \n",
    "}\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "with open(\"results/results.pkl\", \"wb\") as f:\n",
    "    pickle.dump(results, f)\n",
    "print(\"Results saved in results directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shiru",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
