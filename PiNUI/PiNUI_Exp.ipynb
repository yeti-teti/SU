{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import scipy as sp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from rich import print, progress\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Prep "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sequence(seq, max_length=1000):\n",
    "    # Define a mapping for common amino acids\n",
    "    amino_acids = \"ACDEFGHIKLMNPQRSTVWY\"\n",
    "    aa_to_int = {aa: i + 1 for i, aa in enumerate(amino_acids)}  # reserve 0 for padding\n",
    "\n",
    "    # Convert each amino acid in the sequence to its corresponding integer\n",
    "    encoded = [aa_to_int.get(aa, 0) for aa in seq]  # default to 0 if amino acid not found\n",
    "\n",
    "    # Pad or truncate the sequence to max_length\n",
    "    if len(encoded) < max_length:\n",
    "        encoded += [0] * (max_length - len(encoded))\n",
    "    else:\n",
    "        encoded = encoded[:max_length]\n",
    "    return encoded\n",
    "\n",
    "\n",
    "class PiNUIDataset(Dataset):\n",
    "    def __init__(self, seqA, seqB, targets, max_length=1000):\n",
    "        # Encode sequences from strings to numerical lists\n",
    "        self.seqA = [encode_sequence(seq, max_length) for seq in seqA]\n",
    "        self.seqB = [encode_sequence(seq, max_length) for seq in seqB]\n",
    "        self.targets = targets\n",
    "\n",
    "        # Convert the numerical lists and targets to tensors\n",
    "        self.seqA = torch.tensor(self.seqA, dtype=torch.float32)\n",
    "        self.seqB = torch.tensor(self.seqB, dtype=torch.float32)\n",
    "        self.targets = torch.tensor(self.targets, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {'seqA':self.seqA[idx], 'seqB':self.seqB[idx]}, self.targets[idx]\n",
    "    \n",
    "# Prepare dataset for training\n",
    "def prepare_data(train_df, test_df, target='interaction', batch_size=32, max_length=1000):\n",
    "    # Extract sequences and target values\n",
    "    train_seqA = train_df['seqA'].values\n",
    "    train_seqB = train_df['seqB'].values\n",
    "    y_train = train_df[target].values\n",
    "  \n",
    "    test_seqA = test_df['seqA'].values\n",
    "    test_seqB = test_df['seqB'].values\n",
    "    y_test = test_df[target].values\n",
    "  \n",
    "    # Create datasets with encoding\n",
    "    train_dataset = PiNUIDataset(train_seqA, train_seqB, y_train, max_length)\n",
    "    test_dataset = PiNUIDataset(test_seqA, test_seqB, y_test, max_length)\n",
    "  \n",
    "    # Create DataLoaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "  \n",
    "    return train_loader, test_loader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MLP  \n",
    "class PiNUIMLP(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, hidden_dim, dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc3 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "        self.Dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, features_dict):\n",
    "        # Embedding for each seq\n",
    "        seqA = features_dict['seqA']\n",
    "        seqB = features_dict['seqB']\n",
    "\n",
    "        x = torch.stack([\n",
    "            seqA,\n",
    "            seqB\n",
    "        ], dim=1)\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.Dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.sigmoid(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader,test_loader, criterion, optimizer, num_epochs, device='cuda', early_stopping='5'):\n",
    "\n",
    "    model.to(device)\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    training_history = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_predictions = []\n",
    "        train_actuals = []\n",
    "\n",
    "        for batch_features, batch_targets in progress.track(train_loader, description=f\"Epoch {epoch + 1}\"):\n",
    "            \n",
    "            batch_features = {k:v.to(device, non_blocking=True) for k, v in batch_features.items()}\n",
    "            batch_targets = batch_targets.to(device, non_blocking=True).unsqueeze(-1)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_features)\n",
    "            loss = criterion(outputs, batch_targets)\n",
    "            loss.backward()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            train_predictions.extend(outputs.detach().cpu().numpy())\n",
    "            train_actuals.extend(batch_targets.cpu().numpy())\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_predictions = []\n",
    "        val_actuals = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_features, batch_targets in test_loader:\n",
    "                batch_features = {k:v.to(device, non_blocking=True) for k, v in batch_features.items()}\n",
    "                batch_targets = batch_targets.to(device, non_blocking=True)\n",
    "\n",
    "                outputs = model(batch_targets)\n",
    "                v_loss = criterion(outputs, batch_targets)\n",
    "                                \n",
    "                val_loss += v_loss.item()\n",
    "                val_predictions.extend(outputs.cpu().numpy())\n",
    "                val_actuals.extend(outputs.cpu().numpy())\n",
    "\n",
    "        # Metrics\n",
    "        train_loss /= len(train_loader)\n",
    "        val_loss /= len(test_loader)\n",
    "        train_correlation = np.corrcoef(train_actuals, train_predictions)[0,1]\n",
    "        val_correlation = np.corrcoef(val_actuals, val_predictions)[0,1]\n",
    "        \n",
    "        # Append each epoch history\n",
    "        training_history.append({\n",
    "            'epoch': epoch + 1, \n",
    "            'train_loss': train_loss, \n",
    "            'val_loss': val_loss, \n",
    "            'train_correlation': train_correlation,\n",
    "            'val_correlation': val_correlation\n",
    "        })\n",
    "\n",
    "        print(f'\\n Epoch: {epoch + 1}/{num_epochs} ')\n",
    "        print(f'\\n Training loss: {train_loss:.4f}, Correlation: {train_correlation:4f}')\n",
    "        print(f'\\n Validation loss: {val_loss:.4f}, Correlation: {val_correlation:.4f}')\n",
    "\n",
    "        # Early stopping \n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), \"best_model.pth\")\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        if patience_counter >= early_stopping:\n",
    "            print(f'Early stopping after {epoch + 1} epochs')\n",
    "            break\n",
    "    \n",
    "    return pd.DataFrame(training_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, device='cuda'):\n",
    "\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_features, batch_targets in test_loader:\n",
    "            batch_features = {k:v.to(device, non_blocking=True) for k, v in batch_features.items()}\n",
    "            batch_targets = batch_targets.to(device, non_blocking=True)\n",
    "\n",
    "            outputs = model(batch_features)\n",
    "\n",
    "            predictions.extend(outputs.cpu().numpy())\n",
    "            actuals.extend(batch_targets.cpu().numpy())\n",
    "    \n",
    "    return np.array(predictions), np.array(actuals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Loading Data<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Loading Data\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load dataset\n",
    "print(\"Loading Data...\")\n",
    "data_human = pd.read_csv(\"https://shiru-public.s3.us-west-2.amazonaws.com/PiNUI/PiNUI-human.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Preparing dataset<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Preparing dataset\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_6/7t87hdks683bh7l07gtby3740000gn/T/ipykernel_22211/2782287716.py:25: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.seqA = torch.tensor(self.seqA, dtype=torch.float32)\n",
      "/var/folders/_6/7t87hdks683bh7l07gtby3740000gn/T/ipykernel_22211/2782287716.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.seqB = torch.tensor(self.seqB, dtype=torch.float32)\n",
      "/var/folders/_6/7t87hdks683bh7l07gtby3740000gn/T/ipykernel_22211/2782287716.py:27: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.targets = torch.tensor(self.targets, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "# Prepare dataset\n",
    "train_val_proteins, test_proteins = train_test_split(data_human, train_size=0.8)\n",
    "print(\"Preparing dataset...\")\n",
    "train_loader, test_loader = prepare_data(\n",
    "    train_val_proteins, test_proteins, target='interaction', batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'seqA'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span>.,  <span style=\"color: #808000; text-decoration-color: #808000\">...</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.<span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>.,  <span style=\"color: #808000; text-decoration-color: #808000\">...</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>.<span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>.,  <span style=\"color: #808000; text-decoration-color: #808000\">...</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.<span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">...</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17</span>.,  <span style=\"color: #808000; text-decoration-color: #808000\">...</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.<span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>.,  <span style=\"color: #808000; text-decoration-color: #808000\">...</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.<span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span>.,  <span style=\"color: #808000; text-decoration-color: #808000\">...</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.<span style=\"font-weight: bold\">]])</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'seqB'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>.,  <span style=\"color: #808000; text-decoration-color: #808000\">...</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.<span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span>.,  <span style=\"color: #808000; text-decoration-color: #808000\">...</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.<span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span>.,  <span style=\"color: #808000; text-decoration-color: #808000\">...</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.<span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">...</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>.,  <span style=\"color: #808000; text-decoration-color: #808000\">...</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.<span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>.,  <span style=\"color: #808000; text-decoration-color: #808000\">...</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.<span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span>.,  <span style=\"color: #808000; text-decoration-color: #808000\">...</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>.,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>., <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span>.<span style=\"font-weight: bold\">]])</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'seqA'\u001b[0m: \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m11\u001b[0m., \u001b[1;36m11\u001b[0m., \u001b[1;36m13\u001b[0m.,  \u001b[33m...\u001b[0m,  \u001b[1;36m0\u001b[0m.,  \u001b[1;36m0\u001b[0m.,  \u001b[1;36m0\u001b[0m.\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m11\u001b[0m.,  \u001b[1;36m1\u001b[0m.,  \u001b[1;36m4\u001b[0m.,  \u001b[33m...\u001b[0m,  \u001b[1;36m9\u001b[0m., \u001b[1;36m17\u001b[0m.,  \u001b[1;36m4\u001b[0m.\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m11\u001b[0m.,  \u001b[1;36m1\u001b[0m.,  \u001b[1;36m1\u001b[0m.,  \u001b[33m...\u001b[0m,  \u001b[1;36m0\u001b[0m.,  \u001b[1;36m0\u001b[0m.,  \u001b[1;36m0\u001b[0m.\u001b[1m]\u001b[0m,\n",
       "        \u001b[33m...\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m11\u001b[0m., \u001b[1;36m17\u001b[0m., \u001b[1;36m17\u001b[0m.,  \u001b[33m...\u001b[0m,  \u001b[1;36m0\u001b[0m.,  \u001b[1;36m0\u001b[0m.,  \u001b[1;36m0\u001b[0m.\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m11\u001b[0m.,  \u001b[1;36m1\u001b[0m.,  \u001b[1;36m3\u001b[0m.,  \u001b[33m...\u001b[0m,  \u001b[1;36m0\u001b[0m.,  \u001b[1;36m0\u001b[0m.,  \u001b[1;36m0\u001b[0m.\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m11\u001b[0m.,  \u001b[1;36m4\u001b[0m.,  \u001b[1;36m9\u001b[0m.,  \u001b[33m...\u001b[0m,  \u001b[1;36m0\u001b[0m.,  \u001b[1;36m0\u001b[0m.,  \u001b[1;36m0\u001b[0m.\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[32m'seqB'\u001b[0m: \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m11\u001b[0m., \u001b[1;36m17\u001b[0m.,  \u001b[1;36m4\u001b[0m.,  \u001b[33m...\u001b[0m,  \u001b[1;36m0\u001b[0m.,  \u001b[1;36m0\u001b[0m.,  \u001b[1;36m0\u001b[0m.\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m11\u001b[0m., \u001b[1;36m19\u001b[0m., \u001b[1;36m16\u001b[0m.,  \u001b[33m...\u001b[0m,  \u001b[1;36m0\u001b[0m.,  \u001b[1;36m0\u001b[0m.,  \u001b[1;36m0\u001b[0m.\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m11\u001b[0m.,  \u001b[1;36m3\u001b[0m.,  \u001b[1;36m9\u001b[0m.,  \u001b[33m...\u001b[0m,  \u001b[1;36m0\u001b[0m.,  \u001b[1;36m0\u001b[0m.,  \u001b[1;36m0\u001b[0m.\u001b[1m]\u001b[0m,\n",
       "        \u001b[33m...\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m11\u001b[0m., \u001b[1;36m16\u001b[0m.,  \u001b[1;36m6\u001b[0m.,  \u001b[33m...\u001b[0m,  \u001b[1;36m0\u001b[0m.,  \u001b[1;36m0\u001b[0m.,  \u001b[1;36m0\u001b[0m.\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m20\u001b[0m.,  \u001b[1;36m6\u001b[0m.,  \u001b[1;36m6\u001b[0m.,  \u001b[33m...\u001b[0m,  \u001b[1;36m0\u001b[0m.,  \u001b[1;36m0\u001b[0m.,  \u001b[1;36m0\u001b[0m.\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m11\u001b[0m., \u001b[1;36m13\u001b[0m., \u001b[1;36m16\u001b[0m.,  \u001b[33m...\u001b[0m,  \u001b[1;36m2\u001b[0m.,  \u001b[1;36m4\u001b[0m., \u001b[1;36m16\u001b[0m.\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for batch_feature, batch_label in train_loader:\n",
    "    print(batch_feature)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Intializing the Model<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Intializing the Model\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Setting the device<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Setting the device\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Using device: mps\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Using device: mps\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Training the model<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Training the model\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/opt/anaconda3/envs/shiru/lib/python3.13/site-packages/rich/live.py:231: UserWarning: install \"ipywidgets\" for \n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/opt/anaconda3/envs/shiru/lib/python3.13/site-packages/rich/live.py:231: UserWarning: install \"ipywidgets\" for \n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 26\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing device: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining the model...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 26\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluating the model...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     39\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_model.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "Cell \u001b[0;32mIn[51], line 41\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, test_loader, criterion, optimizer, num_epochs, device, early_stopping)\u001b[0m\n\u001b[1;32m     38\u001b[0m batch_features \u001b[38;5;241m=\u001b[39m {k:v\u001b[38;5;241m.\u001b[39mto(device, non_blocking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m batch_features\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m     39\u001b[0m batch_targets \u001b[38;5;241m=\u001b[39m batch_targets\u001b[38;5;241m.\u001b[39mto(device, non_blocking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 41\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_targets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m v_loss \u001b[38;5;241m=\u001b[39m criterion(outputs, batch_targets)\n\u001b[1;32m     44\u001b[0m val_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m v_loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/shiru/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/shiru/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[48], line 16\u001b[0m, in \u001b[0;36mPiNUIMLP.forward\u001b[0;34m(self, features_dict)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, features_dict):\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# Embedding for each seq\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m     seqA \u001b[38;5;241m=\u001b[39m \u001b[43mfeatures_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mseqA\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     17\u001b[0m     seqB \u001b[38;5;241m=\u001b[39m features_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseqB\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     19\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([\n\u001b[1;32m     20\u001b[0m         seqA,\n\u001b[1;32m     21\u001b[0m         seqB\n\u001b[1;32m     22\u001b[0m     ], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for tensor of dimension 1"
     ]
    }
   ],
   "source": [
    "# Main\n",
    "print(\"Intializing the Model...\")\n",
    "model = PiNUIMLP(\n",
    "    input_dim=1000, \n",
    "    output_dim=1, \n",
    "    hidden_dim=256, \n",
    "    dropout=0.1,\n",
    ")\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr = 0.001)\n",
    "num_epochs = 10\n",
    "early_stopping = 5\n",
    "\n",
    "print(\"Setting the device...\")\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    if torch.mps.is_available():\n",
    "        device = 'mps'\n",
    "    else:\n",
    "        device = 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "print(\"Training the model...\")\n",
    "history = train_model(\n",
    "    model, \n",
    "    train_loader, \n",
    "    test_loader, \n",
    "    criterion, \n",
    "    optimizer, \n",
    "    num_epochs, \n",
    "    device, \n",
    "    early_stopping\n",
    ")\n",
    "\n",
    "\n",
    "print(\"Evaluating the model...\")\n",
    "model.load_state_dict(torch.load(\"best_model.pth\"))\n",
    "predictions, actuals = evaluate_model(model, train_loader, device)\n",
    "\n",
    "correlation = np.corrcoef(actuals, predictions)[0,1]\n",
    "print(\"\\n Final correlation: {correlation:.4f}\")\n",
    "\n",
    "# Saving the results\n",
    "results = {\n",
    "    'history': history, \n",
    "    'predictions': predictions, \n",
    "    'actuals': actuals   \n",
    "}\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "with open(\"results/resuls.pkl\", \"wb\") as f:\n",
    "    pickle.dump(results, f)\n",
    "print(\"Results saved in results directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shiru",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
